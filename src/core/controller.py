"""
æ‰§è¡Œæ§åˆ¶å™¨ï¼ˆæ”¯æŒæµå¼è¾“å‡ºï¼‰
æ ¸å¿ƒæ”¹è¿›ï¼š
1. ConversationManagerè´Ÿè´£æ ¼å¼åŒ–å¯¹è¯å†å²
2. å¤ç”¨ContextManager.compress_messagesåšæ™ºèƒ½è£å‰ª
3. æ”¯æŒæµå¼è¾“å‡º (stream_execute æ–¹æ³•)
4. ç»Ÿä¸€ä½¿ç”¨ StreamEventType äº‹ä»¶ç±»å‹

æ³¨æ„ï¼šæ•°æ®åº“äº‹åŠ¡ç®¡ç†ç”± API å±‚è´Ÿè´£ï¼ŒController ä¸ç®¡ç† session ç”Ÿå‘½å‘¨æœŸã€‚
API å±‚åº”é€šè¿‡ä¾èµ–æ³¨å…¥ä¸ºæ¯ä¸ªè¯·æ±‚åˆ›å»ºç‹¬ç«‹çš„ Manager å®ä¾‹ã€‚
"""

from typing import Dict, List, Optional, Any, AsyncGenerator
from uuid import uuid4
from datetime import datetime
from langgraph.types import Command

from core.state import create_initial_state
from core.context_manager import ContextManager
from core.conversation_manager import ConversationManager
from core.events import StreamEventType, finalize_metrics
from tools.implementations.artifact_ops import ArtifactManager
from utils.logger import get_logger

logger = get_logger("ArtifactFlow")


class ExecutionController:
    """
    æ‰§è¡Œæ§åˆ¶å™¨ï¼ˆæ”¯æŒæµå¼è¾“å‡ºï¼‰
    ä½¿ç”¨ConversationManageræ ¼å¼åŒ–å¯¹è¯å†å²
    æä¾›æ‰¹é‡å’Œæµå¼ä¸¤ç§æ‰§è¡Œæ¨¡å¼

    æ³¨æ„ï¼šæ•°æ®åº“äº‹åŠ¡ç®¡ç†ç”± API å±‚è´Ÿè´£ã€‚
    API å±‚åº”åœ¨è¯·æ±‚å¼€å§‹æ—¶åˆ›å»º sessionï¼Œå¹¶é€šè¿‡ä¾èµ–æ³¨å…¥ä¼ å…¥å·²ç»‘å®š repository çš„ Managerã€‚
    """

    def __init__(
        self,
        compiled_graph,
        artifact_manager: Optional[ArtifactManager] = None,
        conversation_manager: Optional[ConversationManager] = None
    ):
        """
        åˆå§‹åŒ–æ‰§è¡Œæ§åˆ¶å™¨

        Args:
            compiled_graph: ç¼–è¯‘åçš„ LangGraph å›¾
            artifact_manager: Artifact ç®¡ç†å™¨ï¼ˆåº”å·²ç»‘å®š repositoryï¼‰
            conversation_manager: å¯¹è¯ç®¡ç†å™¨ï¼ˆåº”å·²ç»‘å®š repositoryï¼‰
        """
        self.graph = compiled_graph
        self.conversation_manager = conversation_manager or ConversationManager()
        self.artifact_manager = artifact_manager or ArtifactManager()

        logger.info("ExecutionController initialized")
    
    async def execute(
        self,
        content: Optional[str] = None,
        thread_id: Optional[str] = None,
        conversation_id: Optional[str] = None,
        parent_message_id: Optional[str] = None,
        message_id: Optional[str] = None,
        resume_data: Optional[Dict] = None,
    ) -> Dict[str, Any]:
        """
        æ‰¹é‡æ‰§è¡Œæ¥å£

        åœºæ™¯1ï¼šæ–°æ¶ˆæ¯
            - å¿…éœ€: content
            - å¯é€‰: conversation_id, parent_message_id

        åœºæ™¯2ï¼šæ¢å¤æƒé™
            - å¿…éœ€: thread_id, conversation_id, message_id, resume_data

        Args:
            content: ç”¨æˆ·æ¶ˆæ¯å†…å®¹
            thread_id: çº¿ç¨‹IDï¼ˆæ¢å¤æ—¶ä½¿ç”¨ï¼‰
            conversation_id: å¯¹è¯ID
            parent_message_id: çˆ¶æ¶ˆæ¯IDï¼ˆåˆ†æ”¯æ—¶ä½¿ç”¨ï¼‰
            message_id: æ¶ˆæ¯IDï¼ˆæ¢å¤æ—¶ä½¿ç”¨ï¼Œç”¨äºæ›´æ–°å“åº”ï¼‰
            resume_data: æ¢å¤æ•°æ® {"type": "permission", "approved": bool}

        Returns:
            æ‰§è¡Œç»“æœå­—å…¸
        """
        # åœºæ™¯1ï¼šæ–°æ¶ˆæ¯
        if content is not None:
            return await self._execute_new_message(
                content=content,
                conversation_id=conversation_id,
                parent_message_id=parent_message_id
            )
        # åœºæ™¯2ï¼šæ¢å¤æƒé™
        elif thread_id and resume_data and conversation_id and message_id:
            return await self._resume_from_permission(
                thread_id=thread_id,
                conversation_id=conversation_id,
                message_id=message_id,
                resume_data=resume_data
            )

        else:
            raise ValueError(
                "Either 'content' (for new message) or "
                "'thread_id + conversation_id + message_id + resume_data' (for resume) required"
            )
    
    async def stream_execute(
        self,
        content: Optional[str] = None,
        thread_id: Optional[str] = None,
        conversation_id: Optional[str] = None,
        parent_message_id: Optional[str] = None,
        message_id: Optional[str] = None,
        resume_data: Optional[Dict] = None,
    ) -> AsyncGenerator[Dict[str, Any], None]:
        """
        æµå¼æ‰§è¡Œæ¥å£

        åœºæ™¯1ï¼šæ–°æ¶ˆæ¯ï¼ˆæµå¼ï¼‰
            - å¿…éœ€: content
            - å¯é€‰: conversation_id, parent_message_id

        åœºæ™¯2ï¼šæ¢å¤æƒé™ï¼ˆæµå¼ï¼‰
            - å¿…éœ€: thread_id, conversation_id, message_id, resume_data

        Args:
            content: ç”¨æˆ·æ¶ˆæ¯å†…å®¹
            thread_id: çº¿ç¨‹IDï¼ˆæ¢å¤æ—¶ä½¿ç”¨ï¼‰
            conversation_id: å¯¹è¯ID
            parent_message_id: çˆ¶æ¶ˆæ¯IDï¼ˆåˆ†æ”¯æ—¶ä½¿ç”¨ï¼‰
            message_id: æ¶ˆæ¯IDï¼ˆæ¢å¤æ—¶ä½¿ç”¨ï¼Œç”¨äºæ›´æ–°å“åº”ï¼‰
            resume_data: æ¢å¤æ•°æ® {"type": "permission", "approved": bool}

        Yields:
            æµå¼äº‹ä»¶å­—å…¸:
            {
                "event_type": "stream" | "metadata" | "complete",
                "data": {...}
            }
        """
        # åœºæ™¯1ï¼šæ–°æ¶ˆæ¯
        if content is not None:
            async for event in self._stream_new_message(
                content=content,
                conversation_id=conversation_id,
                parent_message_id=parent_message_id
            ):
                yield event

        # åœºæ™¯2ï¼šæ¢å¤æƒé™
        elif thread_id and resume_data and conversation_id and message_id:
            async for event in self._stream_resume_from_permission(
                thread_id=thread_id,
                conversation_id=conversation_id,
                message_id=message_id,
                resume_data=resume_data
            ):
                yield event

        else:
            raise ValueError(
                "Either 'content' (for new message) or "
                "'thread_id + conversation_id + message_id + resume_data' (for resume) required"
            )
    
    async def _execute_new_message(
        self,
        content: str,
        conversation_id: Optional[str],
        parent_message_id: Optional[str]
    ) -> Dict[str, Any]:
        """
        å¤„ç†æ–°æ¶ˆæ¯ï¼ˆæ‰¹é‡æ¨¡å¼ï¼‰

        æµç¨‹ï¼š
        1. ç¡®ä¿conversationå­˜åœ¨
        2. è‡ªåŠ¨è®¾ç½®çˆ¶æ¶ˆæ¯IDï¼ˆå¦‚æœæœªæŒ‡å®šï¼‰
        3. è·å–å¯¹è¯å†å²
        4. æ ¼å¼åŒ–å¯¹è¯å†å²
        5. åˆ›å»ºåˆå§‹çŠ¶æ€ï¼ˆåŒ…å«å¯¹è¯å†å²ï¼‰
        6. æ·»åŠ æ¶ˆæ¯åˆ°conversation
        7. æ‰§è¡Œgraph
        8. å¤„ç†ç»“æœï¼ˆä¸­æ–­æˆ–å®Œæˆï¼‰
        """

        # 1. ç¡®ä¿conversationå­˜åœ¨ï¼ˆä½¿ç”¨å¼‚æ­¥æ–¹æ³•ä»¥æ”¯æŒæŒä¹…åŒ–ï¼‰
        if not conversation_id:
            conversation_id = await self.conversation_manager.start_conversation_async()
        else:
            await self.conversation_manager.ensure_conversation_exists(conversation_id)
        
        # 2. è‡ªåŠ¨è®¾ç½®çˆ¶æ¶ˆæ¯IDï¼ˆå¦‚æœæœªæŒ‡å®šï¼‰
        if not parent_message_id:
            parent_message_id = await self.conversation_manager.get_active_branch(conversation_id)
            if parent_message_id:
                logger.debug(f"Auto-set parent_message_id to current active_branch: {parent_message_id}")

        # 3. æ ¼å¼åŒ–å¯¹è¯å†å²ï¼ˆä½¿ç”¨ConversationManagerçš„æ–¹æ³•ï¼‰
        conversation_history = await self.conversation_manager.format_conversation_history_async(
            conv_id=conversation_id,
            to_message_id=parent_message_id
        )
        
        # 4. ç”ŸæˆID
        message_id = f"msg-{uuid4().hex}"
        thread_id = f"thd-{uuid4().hex}"
        
        # 5. è·å–session
        session_id = self._get_or_create_session(conversation_id)
        # 5.5. è®¾ç½® artifact session å¹¶æ¸…é™¤ä¸Šä¸€è½®çš„ä¸´æ—¶ artifacts
        if self.artifact_manager:
            self.artifact_manager.set_session(session_id)
            try:
                await self.artifact_manager.clear_temporary_artifacts(session_id)
            except Exception as e:
                logger.warning(f"Failed to clear temporary artifacts: {e}")
        
        # 6. åˆ›å»ºåˆå§‹çŠ¶æ€
        initial_state = create_initial_state(
            task=content,
            session_id=session_id,
            thread_id=thread_id,
            message_id=message_id,
            conversation_history=conversation_history
        )
        
        logger.info(f"Processing new message in conversation {conversation_id}")
        
        # 7. æ·»åŠ æ¶ˆæ¯åˆ°conversation
        await self.conversation_manager.add_message_async(
            conv_id=conversation_id,
            message_id=message_id,
            content=content,
            thread_id=thread_id,
            parent_id=parent_message_id
        )
        
        # 8. æ‰§è¡Œgraph
        config = {
            "configurable": {"thread_id": thread_id},
            "recursion_limit": 100  # å·¥å…·å¾ªç¯åœ¨ graph å±‚ï¼Œéœ€è¦æ›´é«˜é™åˆ¶
        }
        
        try:
            result = await self.graph.ainvoke(initial_state, config)
            
            # 8. å¤„ç†ç»“æœ
            if result.get("__interrupt__"):
                # æƒé™ä¸­æ–­: __interrupt__ æ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼ŒåŒ…å« Interrupt å¯¹è±¡
                interrupts = result["__interrupt__"]

                # å–ç¬¬ä¸€ä¸ª Interrupt å¯¹è±¡çš„ value å±æ€§
                interrupt_data = interrupts[0].value

                logger.info(f"âš ï¸ Execution interrupted: {interrupt_data['type']}")

                # è¿”å›ä¸­æ–­ä¿¡æ¯ï¼Œå‰ç«¯éœ€ä¿å­˜ conversation_id, message_id, thread_id ç”¨äºåç»­ resume
                return {
                    "success": True,
                    "interrupted": True,
                    "conversation_id": conversation_id,
                    "message_id": message_id,
                    "thread_id": thread_id,
                    "interrupt_type": interrupt_data["type"],
                    "interrupt_data": interrupt_data
                }
            
            else:
                # æ­£å¸¸å®Œæˆ
                response = result.get("graph_response", "")

                # æ›´æ–°conversation response
                await self.conversation_manager.update_response_async(
                    conv_id=conversation_id,
                    message_id=message_id,
                    response=response
                )

                logger.info(f"âœ… Execution completed")

                return {
                    "success": True,
                    "interrupted": False,
                    "conversation_id": conversation_id,
                    "message_id": message_id,
                    "thread_id": thread_id,
                    "response": response
                }

        except Exception as e:
            logger.exception(f"Error in graph execution: {e}")

            # æ›´æ–°é”™è¯¯å“åº”
            error_msg = f"Error: {str(e)}"
            await self.conversation_manager.update_response_async(
                conv_id=conversation_id,
                message_id=message_id,
                response=error_msg
            )
            
            return {
                "success": False,
                "conversation_id": conversation_id,
                "message_id": message_id,
                "thread_id": thread_id,
                "error": str(e)
            }
    
    async def _stream_new_message(
        self,
        content: str,
        conversation_id: Optional[str],
        parent_message_id: Optional[str]
    ) -> AsyncGenerator[Dict[str, Any], None]:
        """
        ğŸ†• å¤„ç†æ–°æ¶ˆæ¯ï¼ˆæµå¼æ¨¡å¼ï¼‰
        
        æµç¨‹ï¼š
        1-6. å‡†å¤‡å·¥ä½œï¼ˆä¸æ‰¹é‡æ¨¡å¼ç›¸åŒï¼‰
        7. ä½¿ç”¨ graph.astream() æµå¼æ‰§è¡Œ
        8. å®æ—¶yieldäº‹ä»¶
        """
        
        # 1-6. å‡†å¤‡å·¥ä½œï¼ˆä¸æ‰¹é‡æ¨¡å¼ç›¸åŒï¼‰
        if not conversation_id:
            conversation_id = await self.conversation_manager.start_conversation_async()
        else:
            await self.conversation_manager.ensure_conversation_exists(conversation_id)

        if not parent_message_id:
            parent_message_id = await self.conversation_manager.get_active_branch(conversation_id)
            if parent_message_id:
                logger.debug(f"Auto-set parent_message_id to current active_branch: {parent_message_id}")

        conversation_history = await self.conversation_manager.format_conversation_history_async(
            conv_id=conversation_id,
            to_message_id=parent_message_id
        )
        
        message_id = f"msg-{uuid4().hex}"
        thread_id = f"thd-{uuid4().hex}"
        
        session_id = self._get_or_create_session(conversation_id)
        if self.artifact_manager:
            self.artifact_manager.set_session(session_id)
            try:
                await self.artifact_manager.clear_temporary_artifacts(session_id)
            except Exception as e:
                logger.warning(f"Failed to clear temporary artifacts: {e}")
        
        initial_state = create_initial_state(
            task=content,
            session_id=session_id,
            thread_id=thread_id,
            message_id=message_id,
            conversation_history=conversation_history
        )
        
        logger.info(f"Processing new message (streaming) in conversation {conversation_id}")

        await self.conversation_manager.add_message_async(
            conv_id=conversation_id,
            message_id=message_id,
            content=content,
            thread_id=thread_id,
            parent_id=parent_message_id
        )
        
        # å…ˆå‘é€å…ƒæ•°æ®äº‹ä»¶
        yield {
            "type": StreamEventType.METADATA.value,
            "timestamp": datetime.now().isoformat(),
            "data": {
                "conversation_id": conversation_id,
                "message_id": message_id,
                "thread_id": thread_id
            }
        }

        # 7-8. æµå¼æ‰§è¡Œgraph
        config = {
            "configurable": {"thread_id": thread_id},
            "recursion_limit": 100  # å·¥å…·å¾ªç¯åœ¨ graph å±‚ï¼Œéœ€è¦æ›´é«˜é™åˆ¶
        }

        try:
            # ä½¿ç”¨ astream() æ›¿ä»£ ainvoke()ï¼Œå¹¶æŒ‡å®š stream_mode="custom"
            final_response = None

            async for chunk in self.graph.astream(
                initial_state,
                config,
                stream_mode="custom"  # å…³é”®ï¼šä½¿ç”¨ custom æ¨¡å¼
            ):
                # chunk æ˜¯ä¸€ä¸ªå­—å…¸ï¼ŒåŒ…å«æˆ‘ä»¬åœ¨ graph ä¸­é€šè¿‡ writer() å‘é€çš„æ•°æ®
                # æ ¼å¼: {"type": "...", "agent": "...", "timestamp": "...", "data": {...}}

                # ç›´æ¥é€ä¼ äº‹ä»¶ï¼ˆå·²ç»æ˜¯ç»Ÿä¸€çš„ StreamEventType æ ¼å¼ï¼‰
                yield chunk

                # æ”¶é›†æœ€ç»ˆå“åº”ï¼ˆä» AGENT_COMPLETE äº‹ä»¶ï¼‰
                if chunk.get("type") == StreamEventType.AGENT_COMPLETE.value and chunk.get("data"):
                    final_response = chunk["data"].get("content", "")

            # æ£€æŸ¥æ˜¯å¦æœ‰ä¸­æ–­
            final_state = await self.graph.aget_state(config)

            # å®Œæˆ execution_metrics
            execution_metrics = final_state.values.get("execution_metrics", {})
            finalize_metrics(execution_metrics)

            # æ³¨æ„ï¼šåœ¨æµå¼æ¨¡å¼ä¸‹ï¼Œä¸­æ–­çš„æ£€æµ‹æ–¹å¼ä¸åŒã€‚åº”æ£€æŸ¥ final_state.interrupts è€Œä¸æ˜¯ values["__interrupt__"]
            if final_state.interrupts:
                # æƒé™ä¸­æ–­
                interrupt_data = final_state.interrupts[0].value

                logger.info(f"âš ï¸ Execution interrupted: {interrupt_data['type']}")

                # å‘é€ä¸­æ–­äº‹ä»¶ï¼Œå‰ç«¯éœ€ä¿å­˜ conversation_id, message_id, thread_id ç”¨äºåç»­ resume
                yield {
                    "type": StreamEventType.COMPLETE.value,
                    "timestamp": datetime.now().isoformat(),
                    "data": {
                        "success": True,
                        "interrupted": True,
                        "conversation_id": conversation_id,
                        "message_id": message_id,
                        "thread_id": thread_id,
                        "interrupt_type": interrupt_data["type"],
                        "interrupt_data": interrupt_data,
                        "execution_metrics": execution_metrics
                    }
                }

            else:
                # æ­£å¸¸å®Œæˆ
                response = final_state.values.get("graph_response", final_response or "")

                await self.conversation_manager.update_response_async(
                    conv_id=conversation_id,
                    message_id=message_id,
                    response=response
                )

                logger.info(f"âœ… Streaming execution completed")

                # å‘é€å®Œæˆäº‹ä»¶ï¼ˆåŒ…å« execution_metricsï¼‰
                yield {
                    "type": StreamEventType.COMPLETE.value,
                    "timestamp": datetime.now().isoformat(),
                    "data": {
                        "success": True,
                        "interrupted": False,
                        "conversation_id": conversation_id,
                        "message_id": message_id,
                        "thread_id": thread_id,
                        "response": response,
                        "execution_metrics": execution_metrics
                    }
                }

        except Exception as e:
            logger.exception(f"Error in streaming graph execution: {e}")

            error_msg = f"Error: {str(e)}"
            await self.conversation_manager.update_response_async(
                conv_id=conversation_id,
                message_id=message_id,
                response=error_msg
            )

            # å‘é€é”™è¯¯äº‹ä»¶
            yield {
                "type": StreamEventType.ERROR.value,
                "timestamp": datetime.now().isoformat(),
                "data": {
                    "success": False,
                    "conversation_id": conversation_id,
                    "message_id": message_id,
                    "thread_id": thread_id,
                    "error": str(e)
                }
            }
    
    async def _resume_from_permission(
        self,
        thread_id: str,
        conversation_id: str,
        message_id: str,
        resume_data: Dict
    ) -> Dict[str, Any]:
        """
        ä»æƒé™ä¸­æ–­æ¢å¤ï¼ˆæ‰¹é‡æ¨¡å¼ï¼‰

        Args:
            thread_id: çº¿ç¨‹ID
            conversation_id: å¯¹è¯ID
            message_id: æ¶ˆæ¯IDï¼ˆç”¨äºæ›´æ–°å“åº”ï¼‰
            resume_data: æ¢å¤æ•°æ® {"type": "permission", "approved": bool}

        Returns:
            æ‰§è¡Œç»“æœ
        """

        logger.info(f"Resuming thread {thread_id} after permission")

        # æ¢å¤ artifact sessionï¼ˆsession_id ä¸ conversation_id ç›¸åŒï¼‰
        if self.artifact_manager:
            self.artifact_manager.set_session(conversation_id)

        # æ¢å¤æ‰§è¡Œ
        config = {
            "configurable": {"thread_id": thread_id},
            "recursion_limit": 100
        }

        try:
            result = await self.graph.ainvoke(
                Command(resume=resume_data.get("approved", False)),
                config
            )

            # æ›´æ–°conversation response
            response = result.get("graph_response", "")
            await self.conversation_manager.update_response_async(
                conv_id=conversation_id,
                message_id=message_id,
                response=response
            )

            logger.info(f"âœ… Resumed execution completed")

            return {
                "success": True,
                "interrupted": False,
                "conversation_id": conversation_id,
                "message_id": message_id,
                "thread_id": thread_id,
                "response": response
            }

        except Exception as e:
            logger.exception(f"Error in resume execution: {e}")

            return {
                "success": False,
                "conversation_id": conversation_id,
                "message_id": message_id,
                "thread_id": thread_id,
                "error": str(e)
            }
    
    async def _stream_resume_from_permission(
        self,
        thread_id: str,
        conversation_id: str,
        message_id: str,
        resume_data: Dict
    ) -> AsyncGenerator[Dict[str, Any], None]:
        """
        ä»æƒé™ä¸­æ–­æ¢å¤ï¼ˆæµå¼æ¨¡å¼ï¼‰

        Args:
            thread_id: çº¿ç¨‹ID
            conversation_id: å¯¹è¯ID
            message_id: æ¶ˆæ¯IDï¼ˆç”¨äºæ›´æ–°å“åº”ï¼‰
            resume_data: æ¢å¤æ•°æ® {"type": "permission", "approved": bool}

        Yields:
            æµå¼äº‹ä»¶
        """

        logger.info(f"Resuming thread {thread_id} after permission (streaming)")

        # æ¢å¤ artifact sessionï¼ˆsession_id ä¸ conversation_id ç›¸åŒï¼‰
        if self.artifact_manager:
            self.artifact_manager.set_session(conversation_id)

        # å‘é€å…ƒæ•°æ®
        yield {
            "type": StreamEventType.METADATA.value,
            "timestamp": datetime.now().isoformat(),
            "data": {
                "conversation_id": conversation_id,
                "message_id": message_id,
                "thread_id": thread_id,
                "resuming": True
            }
        }

        config = {
            "configurable": {"thread_id": thread_id},
            "recursion_limit": 100
        }

        try:
            final_response = None

            async for chunk in self.graph.astream(
                Command(resume=resume_data.get("approved", False)),
                config,
                stream_mode="custom"
            ):
                # ç›´æ¥é€ä¼ äº‹ä»¶
                yield chunk

                if chunk.get("type") == StreamEventType.AGENT_COMPLETE.value and chunk.get("data"):
                    final_response = chunk["data"].get("content", "")

            # è·å–æœ€ç»ˆçŠ¶æ€
            final_state = await self.graph.aget_state(config)

            # å®Œæˆ execution_metrics
            execution_metrics = final_state.values.get("execution_metrics", {})
            finalize_metrics(execution_metrics)

            response = final_state.values.get("graph_response", final_response or "")

            await self.conversation_manager.update_response_async(
                conv_id=conversation_id,
                message_id=message_id,
                response=response
            )

            logger.info(f"âœ… Streaming resumed execution completed")

            yield {
                "type": StreamEventType.COMPLETE.value,
                "timestamp": datetime.now().isoformat(),
                "data": {
                    "success": True,
                    "interrupted": False,
                    "conversation_id": conversation_id,
                    "message_id": message_id,
                    "thread_id": thread_id,
                    "response": response,
                    "execution_metrics": execution_metrics
                }
            }

        except Exception as e:
            logger.exception(f"Error in streaming resume execution: {e}")

            yield {
                "type": StreamEventType.ERROR.value,
                "timestamp": datetime.now().isoformat(),
                "data": {
                    "success": False,
                    "conversation_id": conversation_id,
                    "message_id": message_id,
                    "thread_id": thread_id,
                    "error": str(e)
                }
            }
    
    def _get_or_create_session(self, conversation_id: str) -> str:
        """
        ä¸ºconversationè·å–æˆ–åˆ›å»ºartifact session ID
        ä¸€ä¸ªconversationå¯¹åº”ä¸€ä¸ªartifact session

        æ³¨æ„ï¼šsession_id ä¸ conversation_id ç›¸åŒï¼Œè¿™æ˜¯å› ä¸º ArtifactSession.id
        æ˜¯ Conversation.id çš„å¤–é”®
        """
        return conversation_id
    
    async def get_conversation_history(self, conversation_id: str) -> List[Dict]:
        """è·å–å¯¹è¯å†å²ï¼ˆç”¨äºå±•ç¤ºï¼‰"""
        return await self.conversation_manager.get_conversation_path_async(conversation_id)

    async def list_conversations(self) -> List[Dict]:
        """åˆ—å‡ºæ‰€æœ‰å¯¹è¯"""
        return await self.conversation_manager.list_conversations_async()