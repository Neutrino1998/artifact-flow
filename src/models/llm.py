"""
ç»Ÿä¸€çš„LLMæ¥å£å°è£…
åŸºäºLangChainå®ç°ï¼Œæ”¯æŒOpenAIæ¥å£å…¼å®¹æ¨¡å‹
"""

import os
from typing import Optional, Dict, Any
from dotenv import load_dotenv

from langchain_openai import ChatOpenAI
from ..utils.logger import get_logger

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

logger = get_logger("LLM")


# é¢„å®šä¹‰æ¨¡å‹é…ç½®
MODEL_CONFIGS = {
    # OpenAI
    "gpt-4o": {
        "model": "gpt-4o",
        "api_key": os.getenv("OPENAI_API_KEY"),
    },
    "gpt-4o-mini": {
        "model": "gpt-4o-mini", 
        "api_key": os.getenv("OPENAI_API_KEY"),
    },
    
    # Qwen (é€šä¹‰åƒé—®) - æ ¹æ®æµ‹è¯•ç»“æœæ›´æ–°
    "qwen-max": {
        "model": "qwen-max",
        "api_key": os.getenv("DASHSCOPE_API_KEY"),
        "base_url": "https://dashscope.aliyuncs.com/compatible-mode/v1",
    },
    "qwen-plus": {
        "model": "qwen-plus",
        "api_key": os.getenv("DASHSCOPE_API_KEY"),
        "base_url": "https://dashscope.aliyuncs.com/compatible-mode/v1",
    },
    "qwen-turbo": {
        "model": "qwen-turbo",
        "api_key": os.getenv("DASHSCOPE_API_KEY"),
        "base_url": "https://dashscope.aliyuncs.com/compatible-mode/v1",
    },
    
    # Qwen3-30B ç³»åˆ—æ¨¡å‹ (2507ç‰ˆæœ¬)
    "qwen3-30b-thinking": {
        "model": "qwen3-30b-a3b-thinking-2507",
        "api_key": os.getenv("DASHSCOPE_API_KEY"),
        "base_url": "https://dashscope.aliyuncs.com/compatible-mode/v1",
        "description": "Qwen3-30Bæ€è€ƒæ¨¡å‹ï¼Œæ”¯æŒæ·±åº¦æ¨ç†å’Œé€æ­¥åˆ†æ"
    },
    "qwen3-30b-instruct": {
        "model": "qwen3-30b-a3b-instruct-2507",
        "api_key": os.getenv("DASHSCOPE_API_KEY"),
        "base_url": "https://dashscope.aliyuncs.com/compatible-mode/v1",
        "description": "Qwen3-30BæŒ‡ä»¤æ¨¡å‹ï¼Œå¿«é€Ÿç›´æ¥å›ç­”"
    },
    
    # DeepSeek
    "deepseek-chat": {
        "model": "deepseek-chat",
        "api_key": os.getenv("DEEPSEEK_API_KEY"),
        "base_url": "https://api.deepseek.com/v1",
    },
    "deepseek-reasoner": {
        "model": "deepseek-reasoner",
        "api_key": os.getenv("DEEPSEEK_API_KEY"),
        "base_url": "https://api.deepseek.com/v1",
        "description": "DeepSeekæ¨ç†æ¨¡å‹ï¼Œæ”¯æŒå¤æ‚é€»è¾‘"
    },
}


def create_llm(
    model: str = "gpt-4o-mini",
    temperature: float = 0.7,
    max_tokens: int = 4096,
    streaming: bool = False,
    **kwargs
) -> ChatOpenAI:
    """
    åˆ›å»ºLLMå®ä¾‹
    
    Args:
        model: æ¨¡å‹åç§°ï¼Œå¯ä»¥æ˜¯é¢„å®šä¹‰çš„åç§°æˆ–ç›´æ¥çš„æ¨¡å‹ID
        temperature: æ¸©åº¦å‚æ•°
        max_tokens: æœ€å¤§tokenæ•°
        streaming: æ˜¯å¦æµå¼è¾“å‡º
        **kwargs: å…¶ä»–ChatOpenAIæ”¯æŒçš„å‚æ•°
    
    Returns:
        ChatOpenAIå®ä¾‹
    
    Example:
        # ä½¿ç”¨é¢„å®šä¹‰æ¨¡å‹
        llm = create_llm("qwen-plus")
        response = llm.invoke("Hello!")
        
        # ä½¿ç”¨æ€è€ƒæ¨¡å‹
        llm = create_llm("qwen3-30b-thinking", temperature=0.1)
        response = llm.invoke("è§£é‡Šé‡å­çº ç¼ ")
        
        # æµå¼è¾“å‡º
        llm = create_llm("deepseek-chat", streaming=True)
        for chunk in llm.stream("Tell me a story"):
            print(chunk.content, end="")
    """
    # å¦‚æœæ˜¯é¢„å®šä¹‰æ¨¡å‹ï¼Œä½¿ç”¨é¢„å®šä¹‰é…ç½®
    if model in MODEL_CONFIGS:
        config = MODEL_CONFIGS[model].copy()
        model_name = config.pop("model")
        
        # ç§»é™¤descriptionå­—æ®µï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        config.pop("description", None)
        
        # åˆå¹¶ç”¨æˆ·æä¾›çš„å‚æ•°ï¼ˆç”¨æˆ·å‚æ•°ä¼˜å…ˆï¼‰
        config.update(kwargs)
        
        llm = ChatOpenAI(
            model=model_name,
            temperature=temperature,
            max_tokens=max_tokens,
            streaming=streaming,
            **config
        )
        logger.info(f"Created LLM: {model_name}")
    else:
        # ç›´æ¥ä½¿ç”¨ç”¨æˆ·æä¾›çš„æ¨¡å‹åç§°
        llm = ChatOpenAI(
            model=model,
            temperature=temperature,
            max_tokens=max_tokens,
            streaming=streaming,
            **kwargs
        )
        logger.info(f"Created LLM: {model}")
    
    return llm


def get_available_models() -> list[str]:
    """è·å–æ‰€æœ‰é¢„å®šä¹‰çš„æ¨¡å‹åç§°"""
    return list(MODEL_CONFIGS.keys())


def get_model_info(model: str) -> Dict[str, Any]:
    """è·å–æ¨¡å‹ä¿¡æ¯"""
    if model in MODEL_CONFIGS:
        config = MODEL_CONFIGS[model].copy()
        return {
            "model_id": config["model"],
            "description": config.get("description", ""),
            "provider": "Qwen" if "qwen" in model else "OpenAI" if "gpt" in model else "DeepSeek"
        }
    return {"model_id": model, "description": "", "provider": "Unknown"}


if __name__ == "__main__":
    # ç®€åŒ–çš„æµ‹è¯•ä»£ç 
    print("ğŸ§ª LLMæ¨¡å—æµ‹è¯•")
    print("=" * 40)
    
    # æµ‹è¯•é—®é¢˜ - ä½¿ç”¨éœ€è¦æ¨ç†çš„æ•°å­¦é¢˜æ¥å¯¹æ¯”ä¸¤ä¸ª30Bæ¨¡å‹
    test_question = "ä¸€ä¸ªåœ†çš„åŠå¾„æ˜¯5ï¼Œå¦ä¸€ä¸ªåœ†çš„åŠå¾„æ˜¯3ï¼Œå¦‚æœè¿™ä¸¤ä¸ªåœ†å¤–åˆ‡ï¼Œæ±‚å®ƒä»¬åœ†å¿ƒä¹‹é—´çš„è·ç¦»ã€‚"
    
    # æµ‹è¯•å¯ç”¨çš„æ¨¡å‹ (åŒ…å«ä¸¤ä¸ª30Bæ¨¡å‹å¯¹æ¯”)
    test_models = ["qwen-turbo", "qwen3-30b-thinking", "qwen3-30b-instruct"]
    
    for model_name in test_models:
        print(f"\nğŸ¤– æµ‹è¯•æ¨¡å‹: {model_name}")
        print("-" * 30)
        
        try:
            # æ£€æŸ¥API Key
            config = MODEL_CONFIGS.get(model_name, {})
            api_key = config.get("api_key")
            
            if not api_key:
                print(f"âŒ è·³è¿‡: æœªè®¾ç½®API Key")
                continue
            
            # åˆ›å»ºæ¨¡å‹å¹¶æµ‹è¯•
            llm = create_llm(model_name, temperature=0.3)
            response = llm.invoke(test_question)
            
            print(f"âœ… è°ƒç”¨æˆåŠŸ")
            print(f"ğŸ“ é—®é¢˜: {test_question}")
            print(f"ğŸ’¬ å›ç­”: \n{response.content}")
            
            print(f"ğŸ“Š å›ç­”é•¿åº¦: {len(response.content)} å­—ç¬¦")
            
        except Exception as e:
            print(f"âŒ è°ƒç”¨å¤±è´¥: {str(e)}")
    
    # æ˜¾ç¤ºæ‰€æœ‰å¯ç”¨æ¨¡å‹
    print(f"\nğŸ“‹ é¢„å®šä¹‰æ¨¡å‹åˆ—è¡¨:")
    for model in get_available_models():
        info = get_model_info(model)
        print(f"   {model}: {info['model_id']} ({info['provider']})")
        if info['description']:
            print(f"      {info['description']}")
    
    print(f"\nâœ… æµ‹è¯•å®Œæˆ")